# huggingface_model_deployment

## TODO:
- [X] Upload model to HuggingFace modelhub
- [X] Productionize and modularize code
- [X] Makefile
- [X] Dockerize
    - [X] Integrate poetry
    - [X] Separate the fastAPI backend and gradio frontend services in different containers
    - [X] Handle them with Docker compose
- [X] CI/CD
    - [X] Use a self-hosted CI/CD runner
    - [X] Use a self-hosted docker image repository
    - [X] Self-host the deployment environment
    - [X] Clean-up old images/containers on the prod server
    - [X] Enable image caching in the self-hosted runner
    - [X] Create an automated release when a new tag is created
- [ ] Pytest / doctest - unit/system tests
- [ ] Nox/Tox
- [ ] Mypy  - typechecking
- [ ] Linting
- [ ] Logging
- [ ] Kafka
- [ ] Prometheus, Grafana, Loki
- [ ] Training/Validation/Testing scripts and modularity
- [ ] Documentation (MkDocs / Sphinx) + Docstrings
- [ ] Kubernetes/Kserve/Helmchart + GPU
- [ ] Model tracking, drift, automated retraining
- [ ] Airflow/Dagster/Argo
- [IN PROGRESS] Create an diagram for the entire architecture (CI/CD, model retraining, etc.)
- [ ] OPTIONAL: Deploy in AWS - EC2 or ECS
- [ ] OPTIONAL: Terraform/Ansible for infrastructure
